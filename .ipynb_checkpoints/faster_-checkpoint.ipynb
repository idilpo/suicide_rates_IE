{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nentry_urls = []\\n\\nstart_date = \"2006-07-02\"\\nend_date = \"2006-07-05\"\\n#base_url = \"https://rip.ie/death-notice/s/all?page={}&start={}+00%3A00%3A00&end={}&sortField=a.createdAtCastToDate&sortDir=DESC&view=list\"\\np_count = 1\\n\\nfor p in range(1, p_count+1):\\n    base_url = \"https://rip.ie/death-notice/s/all?page=\" + str(p) + \"&start=\" + start_date + \"+00%3A00%3A00&end=\" + end_date + \"&sortField=a.createdAtCastToDate&sortDir=DESC&view=list\"\\n    #entry_urls.append(base_url.format(p, start_date, end_date))\\n    entry_urls.append(base_url)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "entry_urls = []\n",
    "\n",
    "start_date = \"2006-07-02\"\n",
    "end_date = \"2006-07-05\"\n",
    "#base_url = \"https://rip.ie/death-notice/s/all?page={}&start={}+00%3A00%3A00&end={}&sortField=a.createdAtCastToDate&sortDir=DESC&view=list\"\n",
    "p_count = 1\n",
    "\n",
    "for p in range(1, p_count+1):\n",
    "    base_url = \"https://rip.ie/death-notice/s/all?page=\" + str(p) + \"&start=\" + start_date + \"+00%3A00%3A00&end=\" + end_date + \"&sortField=a.createdAtCastToDate&sortDir=DESC&view=list\"\n",
    "    #entry_urls.append(base_url.format(p, start_date, end_date))\n",
    "    entry_urls.append(base_url)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "antrim_entry_urls = []\n",
    "\n",
    "for p in range(1, 40):\n",
    "    antrim_base_url = \"https://rip.ie/death-notice/s/antrim?page=\" + str(p) + \"&start=2006-07-02+00%3A00%3A00&end=today&sortField=a.createdAtCastToDate&sortDir=DESC&view=list\"\n",
    "    antrim_entry_urls.append(antrim_base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data from {url}. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing {url}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_html(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ID(url):\n",
    "    url_pattern = r'https://rip.ie/death-notice/([^/]+)-([^/]+)-([^/]+)(?:-([^/]+))?-(\\d+)'\n",
    "    m = re.match(url_pattern, url)\n",
    "    if m:\n",
    "        return m.group(5)  \n",
    "    else:\n",
    "        print(\"Pattern did not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(soup):\n",
    "    url_list = []\n",
    "    anchors = soup.find_all('a', class_='showdown-dn-link')\n",
    "    urls = [anchor['href'] for anchor in anchors]\n",
    "    for url in urls:\n",
    "        url_list.append(\"https://rip.ie\" + url)\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(soup):\n",
    "    name_val = soup.find('h1', class_='DeathNotice_person-name__lkvex')\n",
    "    if name_val:\n",
    "        name = name_val.get_text()\n",
    "        name = name.strip()\n",
    "        name = name.replace(\"Â\", \"\")\n",
    "        name = name.replace(\"nee\", \"née\")\n",
    "        name = name.replace(\"nÃ©e\", \"née\")\n",
    "        name = name.replace(\"\\n\", \" \")\n",
    "        name = name.replace(\"â\", \"’\")\n",
    "        return name\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc(soup):\n",
    "    locations = {}\n",
    "    loc_val = soup.find('div', class_='DeathNotice_tags-item__Fp1X4')\n",
    "    if loc_val:\n",
    "        raw_loc = loc_val.get_text()\n",
    "        loc = [word.strip() for word in raw_loc.split(\",\") + raw_loc.split(\"/\")]\n",
    "        city_town = loc[-1]\n",
    "        locations[\"City\"] = city_town.split(\",\")[-1]\n",
    "        locations[\"Town\"] = city_town.split(\",\")[:-1]\n",
    "        return locations\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(soup):\n",
    "    date_list = {}\n",
    "\n",
    "    published_date_value = soup.find('p', class_='DeathNotice_dates-published-date__M0A_i')\n",
    "    if published_date_value:\n",
    "        date_list[\"Published Date\"] = published_date_value.get_text()\n",
    "    else:\n",
    "        date_list[\"Published Date\"] = None\n",
    "\n",
    "    death_date_value = soup.find('p', class_='DeathNotice_dates-death-date__bR7g_')\n",
    "    if death_date_value:\n",
    "        date_list[\"Death Date\"] = death_date_value.get_text()\n",
    "    else:\n",
    "        date_list[\"Death Date\"] = None\n",
    "\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obituary(soup):\n",
    "    description = soup.find('div', class_='DeathNotice_description__sY_tC word-break')\n",
    "    if description:\n",
    "        text = description.get_text()\n",
    "        text = text.strip()\n",
    "        text = text.replace(\"Â\", \"\")\n",
    "        text = text.replace(\"nee\", \"née\")\n",
    "        text = text.replace(\"nÃ©e\", \"née\")\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        text = text.replace(\"â\", \"’\")\n",
    "        text = text.replace(\"Å\", \"\")\n",
    "        text = text.replace(\"Ä\", \"\")\n",
    "        text = text.replace(\"\", \"\")\n",
    "        return text\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_data(entry_urls):\n",
    "    data_list = []\n",
    "\n",
    "    for entry_url in entry_urls:\n",
    "        page_data = re_url(entry_url)\n",
    "        if page_data:\n",
    "            url_list = get_url(scrape_html(page_data))\n",
    "            \n",
    "    for u in url_list:\n",
    "        s = scrape_html(re_url(u))\n",
    "        identity = get_ID(u)\n",
    "        name = get_name(s)\n",
    "        loc = get_loc(s)\n",
    "        dates = get_dates(s)\n",
    "        obituary_text = get_obituary(s)\n",
    "\n",
    "        data_list.append({\n",
    "            \"Name\": name,\n",
    "            \"ID\": identity,\n",
    "            \"City\": loc[\"City\"],\n",
    "            \"Town\": loc[\"Town\"],\n",
    "            \"Published Date\": dates[\"Published Date\"],\n",
    "            \"Death Date\": dates[\"Death Date\"],\n",
    "            \"Obituary Text\": obituary_text\n",
    "    })\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rip_df = get_page_data(antrim_entry_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/Users/idilbilgic/Desktop/STAGE4.1/COMP30170/suicide_rates_IE/output_monthly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m output_directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/idilbilgic/Desktop/STAGE4.1/COMP30170/suicide_rates_IE/output_monthly\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m rip_df\u001b[39m.\u001b[39;49mto_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(output_directory, \u001b[39m'\u001b[39;49m\u001b[39mrip_output_antrim.csv\u001b[39;49m\u001b[39m'\u001b[39;49m), index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3891\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3893\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3894\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3895\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3899\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3900\u001b[0m )\n\u001b[0;32m-> 3902\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3903\u001b[0m     path_or_buf,\n\u001b[1;32m   3904\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[1;32m   3905\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3906\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3907\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3908\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3909\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3910\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3911\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3912\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3913\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3914\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3915\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3916\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3917\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3918\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3919\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/formats/format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1134\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1135\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1151\u001b[0m )\n\u001b[0;32m-> 1152\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1154\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1155\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/formats/csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    248\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[1;32m    249\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    250\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    251\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[1;32m    252\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[1;32m    253\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    254\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    255\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    257\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    258\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    266\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[0;32m--> 739\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[1;32m    741\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[1;32m    742\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    743\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    602\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[1;32m    603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/Users/idilbilgic/Desktop/STAGE4.1/COMP30170/suicide_rates_IE/output_monthly'"
     ]
    }
   ],
   "source": [
    "output_directory = '/Users/idilbilgic/Desktop/STAGE4.1/COMP30170/suicide_rates_IE/output_monthly'\n",
    "rip_df.to_csv(os.path.join(output_directory, 'rip_output_antrim.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rip_df.to_csv('rip_output_2006.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
